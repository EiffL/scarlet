{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Guide"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    `astropy`_, `matplotlib`_, and execution of the following initialization cell\n",
    "    are required to execute some of the code on this page.\n",
    "\n",
    ".. _matplotlib: https://matplotlib.org\n",
    ".. _astropy: http://www.astropy.org"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    There will be API changes in the future to optimize the code and enable additional features. Nonetheless, the code is fully functional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The purpose of this guide is to explain the basic concepts of the *scarlet* package and how they are used. We also show how they can be extended and customized for more specialized science cases.\n",
    "The [API Documentation](api_docs.rst) contains more detailed descriptions of the modules and classes used in *scarlet*, and a more rigorous overview of the mathematics and algorithms used by *scarlet* is described in [Moolekamp & Melchior 2018](https://arxiv.org/abs/1708.09066) and [Melchior et al. 2018](https://arxiv.org/abs/1802.10157).\n",
    "\n",
    "### Basic Concepts and Structure\n",
    "\n",
    "*scarlet* is designed to separate sources in astrophysical images by assuming that each scene can be thought of as a collection of multiple [Source](source.ipynb#scarlet.source.Source) objects.\n",
    "Each [Source](source.ipynb#scarlet.source.Source) can be made up of multiple components, where each component has a single morphology (shape) and uniform spectrum (or SED) with a set of [Constraints](constraints.ipynb#scarlet.constraints.Constraint) they need to obey.\n",
    "The [Source](source.ipynb#scarlet.source.Source) class is a base class, from which specialized classes can be derived to adjust to the sitation at hand. \n",
    "This customization can comprise the number of source components, their initialization, and the constraints they need to obey, or all of those.\n",
    "\n",
    "The [Blend](blend.ipynb#scarlet.blend.Blend) class contains all of the information about the scene, i.e. the collection of Sources, as well as routines for fitting the joint model to data.\n",
    "It implements the minimization algorithm described in [Moolekamp & Melchior 2018](https://arxiv.org/abs/1708.09066).\n",
    "Below is a very brief summary of the method:\n",
    "\n",
    "The deblending algorithm forms a model of the scene\n",
    "\n",
    "$$\\mathsf{M}= \\sum_{k=1}^K \\mathsf{A}_k^T \\times \\mathsf{S}_k = \\mathsf{A}\\mathsf{S}, $$\n",
    "\n",
    "where $\\mathsf{A}_k \\in \\mathbb{R}^B$ is the normalized SED and $\\mathsf{S}_k \\in \\mathbb{R}^N$ is the morphology of a single component in the model with $B$ bands and $N$ pixels in each band.\n",
    "It is important to note that this matrix factorization implies that SEDs and morphologies are independent, e.g. the SED of a component does not change over the region covered by its morphology.\n",
    "\n",
    "The scene is fit by minimizing the likelihood of the model, namely minimizing\n",
    "\n",
    "$$f(\\mathsf{A},\\mathsf{S}) = \\frac{1}{2} || \\mathsf{Y}-\\mathsf{A}\\mathsf{S} ||_2^2, $$\n",
    "\n",
    "where $\\mathsf{Y}$ is an image cube and $||.||_2$ is the element-wise $L_2$ (Frobenius) norm.\n",
    "\n",
    "Each component $j$ can have $M_j$ different constraint functions $g_{ji}$, equivalent to minimizing\n",
    "\n",
    "$$f(\\mathsf{A}, \\mathsf{S}) + \\sum_{j=1}^K \\sum_{i=1}^{M_j} g^A_{ji} \\left(\\mathsf{A}_{ji} \\right) + g^S_{ji} \\left(\\mathsf{S}_{ji} \\right)$$\n",
    "\n",
    "Those constraints are applied to each source in the form of proximal operators, a handy mathematical approach for imposing non-smooth constraints that (if properly formulated) are guaranteed to converge; the curious reader will find more details in [Parikh & Boyd 2014](http://www.web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf) and [Combettes & Pesquet 2011](https://link.springer.com/chapter/10.1007/978-1-4419-9569-8_10).\n",
    "In short, proximal operators map an input vector to the nearest vector that satisfied the respective constraint.\n",
    "Many constraints/penalty functions have analytic proximal operators. \n",
    "\n",
    "*scarlet* allows for two different kinds of constraints: proximal operators in the direct domain (that is directly on the SEDs $\\mathsf{A}_k$ and morphologies $\\mathsf{S}_k$) or in the transformed domain, i.e. after SEDs and morphologies are transformed by a linear operator $\\mathsf{L}$ that is specified by the user. Any linear operator is allowed (it does not have to be invertible), examples are finite differences or basis transforms. The main reason for working in the transformed domain is that it can be much easier to express the constraint, for instance that a particular solution have only one Fourier coefficient.\n",
    "\n",
    "Proximal operators for the direct and transformed domain behave differently. The former can be thought of as *strictly* obeyed at every iteration, while the latter ones will converge to a solution that obeys the constraint eventually. \n",
    "To see this it is useful to understand how $\\mathsf{A}$ and $\\mathsf{S}$ are updated:\n",
    "\n",
    "$$ x^{\\textrm{it}+1} \\leftarrow \\textrm{prox}_{\\lambda f} \\left( x^{\\textrm{it}} - \\frac{\\lambda}{\\rho} \\mathsf{L}^T \\left( \\mathsf{L} x^{\\textrm{it}}-z^{\\textrm{it}} + u^{\\textrm{it}} \\right) \\right)$$\n",
    "\n",
    "$$z^{\\textrm{it}+1} \\leftarrow \\textrm{prox}_{\\rho g} \\left( \\mathsf{L} x^{\\textrm{it}+1} + u^{\\textrm{it}} \\right)$$\n",
    "\n",
    "$$u^{\\textrm{it}+1} \\leftarrow u^{\\textrm{it}} + \\mathsf{L} x^{\\textrm{it}+1} - z^{\\textrm{it}+1}$$\n",
    "\n",
    "where $x^{\\textrm{it}}$ denotes either $\\mathsf{A}_k$ or $\\mathsf{S}_k$ in the current iteration, and $\\textrm{prox}_f$ performs (at least) a step in the direction of the negative gradient of the log-likelihood. $\\textrm{prox}_g$ is the proximal operator in the transformed domain as it acts on $\\mathsf{L} x$ instead of $x$.\n",
    "If additional constraints in the direct domain are present, they will be subsumed in $\\textrm{prox}_f$, thus making sure that they are satisfied in every iteration."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    It is the prime responsibility of the user to choose the appropriate sources (including constraints) that are useful to model a given scene.\n",
    "    Changes to the functionality of `Blend` are normally not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "The base [Source](source.ipynb#scarlet.source.Source) class requires an initial guess for the SED and morphology of each source (in fact, a list of seds and morphologies to support multi-component sources, e.g. bulge-disc models).\n",
    "Most users might want to use derived classes [PointSource](source.ipynb#scarlet.source.PointSource) and [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource), which initialize with a first guess of the morphology and SED from the image cube, and use symmetry, monotonicity, and positivity constraints.\n",
    "Users with more specific needs can create [custom sources](#Custom-Sources).\n",
    "\n",
    "### Object Detection\n",
    "\n",
    "Before we start, we need to load an example image (here an image cube with 5 bands) *and* a detection catalog.\n",
    "If such a catalog is not available, packages like [SEP](http://sep.readthedocs.io/) or [photutils](https://photutils.readthedocs.io/en/stable/) will happily generate one.\n",
    "Instead, we will simply load the truth catalog of the simulation.\n",
    "While not fundamentally needed, *scarlet* works best if the background noise levels are known as well, so we'll also set it to the truth value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='inferno')\n",
    "matplotlib.rc('image', interpolation='none')\n",
    "\n",
    "import numpy as np\n",
    "import scarlet\n",
    "\n",
    "# Load the sample images\n",
    "data = np.load(\"../data/test_sim/data.npz\")\n",
    "images = data[\"images\"]\n",
    "\n",
    "# Load the thruth detection catalog\n",
    "from astropy.table import Table as ApTable\n",
    "catalog = ApTable.read(\"../data/test_sim/true_catalog.fits\")\n",
    "bg_rms = np.array([20]*len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Fundamentally, a [Source](source.ipynb#scarlet.source.Source) needs to hold an SED and morphology.\n",
    "A simple, one-pixel [Source](source.ipynb#scarlet.source.Source) with a SED taken from the center of the image can be set up like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B, Ny, Nx = images.shape\n",
    "center = (Ny//2, Nx//2)\n",
    "# Get the SED at the location of the central pixel, format (1, B) for one component\n",
    "sed = np.expand_dims(scarlet.source.get_pixel_sed(images, center), axis=0)\n",
    "# Set the morphology such that only the central pixel has any intensity\n",
    "morph = np.zeros((Ny, Nx))\n",
    "morph[center] = 1\n",
    "morph = np.expand_dims(morph, axis=0) # format (1, Ny, Nx) for one component\n",
    "src = scarlet.Source(sed=sed, morph=morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources will typically have a `center` (position) argument, but it's not required as some source types are not (well) localized.\n",
    "\n",
    "The location of the center can be re-adjusted to improve localization and to better satisfy constraints like symmetry and monotonicity, which are evaluated with respect to the center.\n",
    "This is done by calculating the dipole of the residuals when shifting the model by `shift_center`, typically a fraction of a pixel.\n",
    "If there is a good reason to believe that the initial positions are correct (such as in simulations), one can set `shift_center=0`.\n",
    "\n",
    "In general, most sources only cover a small region of the full image, it is therefore more computationally efficient to initialize the source in the smallest possible frame (or bounding box).\n",
    "When the entire blend is fit, the size of this frame is recalculated if `fix_frame` is `False` (the default value).\n",
    "\n",
    "One can also prevent the fitting procedure to prevent changes to SED or morphology by setting `fix_sed` or `fix_morph` to `True` (default is `False`).\n",
    "\n",
    "While using the [Source](source.ipynb#scarlet.source.Source) base class is perfectly valid, it is more common to initialize a source using an inherited class.\n",
    "For example, [PointSource](source.ipynb#scarlet.source.PointSource) creates a new source given a `center` position using the SED of the pixel at that location in each band with only that single pixel turned on in the morphology, which is a decent starting configuration for stars.\n",
    "A more generally useful class is [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource), which initializes a source with a symmetric and monotonic model around the `center` location, using the mean SED over that footprint.\n",
    "\n",
    "For example, to create a list of extendend sources for every source in the input catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = [scarlet.source.ExtendedSource((src['y'],src['x']), images, bg_rms) for src in catalog]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource) has a few additional arguments compared to the [Source](source.ipynb#scarlet.source.Source) base class.\n",
    "It requires `img` to determine the initial SED and morphology and the background level `bg_rms` to determine to size of the frame (or bounding box)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    Note in the code above that coordinates in *scarlet* use the traditional C/numpy notation (y,x) as opposed to the mathematical (x,y) ordering. A common error when first starting out with *scarlet* is to mix the order of x and y in your catalog or source list, which can have adverse affects on the results of the deblender."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    It is possible to fix the position of a single source while recentering other sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "\n",
    "### Introduction\n",
    "*scarlet* is implemented in a modular and flexible way that allows users to implement custom constraints tailored to the situations at hand.\n",
    "\n",
    "When specifying a constraint the user can choose what quantity is affected, and how. The [Constraint](constraints.ipynb#scarlet.constraints.Constraint) base class holds these members:\n",
    "```\n",
    "prox_sed\n",
    "prox_morph\n",
    "prox_g_sed\n",
    "L_sed\n",
    "prox_g_morph\n",
    "L_morph\n",
    "source\n",
    "```\n",
    "The operators are called `prox_<sed/morph>` in the direct domain and `prox_g_<sed/morph>` in the transformed domain, for reasons that should be clear from the equations [above](#Basic-Concepts-and-Structure).\n",
    "Any of the members above can be `None`, which implies that they are mute.\n",
    "If `L_<sed/morph> is None` and `prox_g_<sed/morph>` is set, we assume the the transformation matrix $\\mathsf{L}$ is the identity.\n",
    "\n",
    "Multiple constraints can be combined with the `&` operator into a [ConstraintList](constraints.ipynb#scarlet.constraints.ConstraintList). This allows for arbitrary combinations of constraints.\n",
    "For example, the [MinimalConstraint](constraints.ipynb#scarlet.constraints.MinimalConstraint), which requires the SED to have non-negative elements that sum to unity and the morphology to be non-negative, can be combined with an [L0Constraint](constraints.ipynb#scarlet.constraints.L0Constraint) using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scarlet.constraints as sc\n",
    "constraint = sc.MinimalConstraint() & sc.L0Constraint(0.1)\n",
    "constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the direct constraints for the sed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint.prox_sed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which shows (as expected) that the sed must be positive and sum to unity.\n",
    "\n",
    "We also see that there are no constraints in the transformed domain and consequently also no linear operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(constraint.prox_g_sed)\n",
    "print(constraint.prox_g_morph)\n",
    "print(constraint.L_sed)\n",
    "print(constraint.L_morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we get a surprise when we look at direct operator for the morphology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint.prox_morph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`proxmin.operators.AlternatingProjections` is a helper class that is automatically constructed when there are multiple direct-domain constraints (we asked for a L0 penalty *and* positivity).\n",
    "The order *is* important.\n",
    "We adopt the same ordering as with linear operators, starting with the right-most one of the `scarlet.constraints.ConstraintList`, here the L0 penalty, then the positivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint.prox_morph.operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the direct-domain constraints might not commute, in some caes the proximal operators in an `AlternatingProjections` object might want to be repeated several times in a single iterations of the fit.\n",
    "To allow for repeated projections in a single iteration use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint = sc.ConstraintList(constraints=[sc.MinimalConstraint(), sc.L0Constraint(0.1)], repeat=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to repeat all of the alternating projections `3` times in each iteration of *scarlet*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symmetry\n",
    "\n",
    "Demanding that astrophysical sources are symmetric reduces the number of effective degrees of freedom of the model, and most galaxies are *largely* symmetric.\n",
    "The idea has been used successfully in the SDSS deblender and also in our tests on substantially deeper HSC images.\n",
    "\n",
    "Symmetry can be enforced in either the direct or transformed domain, where the former has the ability to specify how strictly symmetry is enforced (for example grand design spirals, irregular galaxies, and jets are not perfectly symmetric and it can be useful to use a softer penalty).\n",
    "\n",
    "#### Direct Symmetry\n",
    "\n",
    "Direct symmetry imposes the [prox_soft_symmetry](operators.ipynb#scarlet.operators.prox_soft_symmetry) projection operator:\n",
    "\n",
    "$$ \\textrm{prox}_\\textrm{sym} = \\frac{\\sigma}{2} \\left( S_k + S_k^\\dagger \\right) + \\left(1-\\sigma \\right) S_k $$\n",
    "\n",
    "where $S_k$ is the flattened morphology matrix for a single source and $S_k^\\dagger$ is it's symmetric version.\n",
    "So the parameter $\\sigma \\in [0,1]$ determines the minimum symmetry required, where $\\sigma=0$ imposes no symmetry constraint at all while $\\sigma=1$ enforces perfect symmetry.\n",
    "\n",
    "We can combine a direct symmetry constraint with the minimal constraint using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint = sc.MinimalConstraint() & sc.DirectSymmetryConstraint(sigma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Symmetry in the Transformed Domain\n",
    "\n",
    "In the transformed domain symmetry is implemented using a linear matrix $\\mathsf{L}=$[getSymmetryOp](transformations.ipynb#scarlet.transformations.getSymmetryOp), which encodes the difference between each pixel and it's symmetric partner, and the proximal operator `proxmin.operators.prox_zero` forces the transformed variable to be zero.\n",
    "As stated in the previous subsection, this constraint is not strictly met in any given iteration but will converge over time to a solution with a symmetric morphology.\n",
    "\n",
    "We can combine this constraint with the minimal `constraint` using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint = sc.MinimalConstraint() & sc.SymmetryConstraint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that our constraint has a `prox_g_morph` but still no `L_morph`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(constraint.prox_g_morph)\n",
    "print(constraint.L_morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the linear operator can't be built until the source is initialized (because it needs to know the shape of the morphology).\n",
    "If we initialize a source with this constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = scarlet.source.PointSource((catalog[\"y\"][0], catalog[\"x\"][0]),\n",
    "                                 img=images, shape=(15, 15),\n",
    "                                 constraints=constraint)\n",
    "print(constraint.L_morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that the linear operator has in fact been created.\n",
    "\n",
    "### Monotonicity\n",
    "\n",
    "Another useful constraint from the SDSS-HSC deblender is the approximation that most astrophysical objects are monotonically decreasing from the peak.\n",
    "In detail this assumption is violated e.g. in spiral galxies, especially tightly wound ones.\n",
    "But if we think of spirals as a single source made up of multiple components, each monotonically decreasing from it's peak with a single SED, we can build a model that is well representative of even morphologically complex galaxies.\n",
    "This point of view has the added benefit that regions that are not monotonically decreasing in a galaxy are likely different stellar populations with (potentially) different SED's and should be treated as separate components anyway.\n",
    "\n",
    "Monotonicity in *scarlet* is implemented in the direct and transformed domain, so we will look at each use to see their differences.\n",
    "The easier one to understand is in the transformed domain: the [MonotonicityConstraint](constraints.ipynb#scarlet.constraints.MonotonicityConstraint) class builds a [getRadialMonotonicOp](transformations.ipynb#scarlet.transformations.getRadialMonotonicOp) linear operator that takes the differences between the flux in the reference pixels and the flux in the current pixel.\n",
    "The transformed morphology vector is then passed on to the `proxmin.operators.prox_plus` proximal operator to project it onto the subspace where all values are non-negative.\n",
    "If `use_nearest` is `True`, only a single reference pixel is used: the nearest one in the direction to the peak.\n",
    "Otherwise a weighted average of all pixels closer to the peak than the current pixel is used to allow for a smoother monotonic solution.\n",
    "\n",
    "| ![](images/nearest_ref.png) | ![](images/weighted_ref.png) |\n",
    "|:---------------------------:|:----------------------------:|\n",
    "| Nearest Neighbor            | Weighted Reference           |\n",
    "\n",
    "\n",
    "In the following example, for simplicity we use the [PointSource](source.ipynb#scarlet.source.PointSource) class to create a source with a simple initial SED and morphology, but add both a [SymmetryConstraint](constraints.ipynb#scarlet.constraints.SymmetryConstraint) and a [MonotonicityConstraint](constraints.ipynb#scarlet.constraints.MonotonicityConstraint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize a constraint that is used for all of the sources\n",
    "constraint = (\n",
    "    sc.SimpleConstraint() # sed sum to unity, all elements of SED and morph are non-negative\n",
    "    & sc.MonotonicityConstraint(use_nearest=False) # prox_g monotonicity\n",
    "    & sc.DirectSymmetryConstraint() # prox_f perfect symmetry\n",
    ")\n",
    "# Initialize the Sources\n",
    "sources = [scarlet.source.PointSource(\n",
    "    (src['y'],src['x']), # center coordinates in `images`\n",
    "    images, # data cube (bands, Ny, Nx)\n",
    "    (15,15), # initial shape of the bounding box\n",
    "    constraints=constraint.copy(), # A copy of the constraint\n",
    ") for src in catalog]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    When creating a list of sources that all use the same constraint, don't forget to use the `copy` method of the `Constraint` class. Some constraints contain parameters specific to the an individual source and are initialized later, so naively using `constraints=constraint` in the `PointSource` initialization above would result in a single `constraint` that is shared by all of the sources and will likely cause the code to crash, or at best give unexpected results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a blended scene with all of the sources, and add a helper method to display the model nicely.\n",
    "We'll discuss the [Blend](blend.ipynb#scarlet.blend.Blend) class later, but for now we just use it to run a few iterations to see the monotonicity constraint in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scarlet.display\n",
    "\n",
    "# Display the sources\n",
    "def display_sources(sources, norm=None, subset=None, combine=False, show_sed=True):\n",
    "    \"\"\"Display the data and model for all sources in a blend\n",
    "    \n",
    "    This convenience function is used to display all (or a subset) of\n",
    "    the sources and (optionally) their SED's.\n",
    "    \"\"\"\n",
    "    if subset is None:\n",
    "        # Show all sources in the blend\n",
    "        subset = range(len(sources))\n",
    "    for m in subset:\n",
    "        # Load the model for the source\n",
    "        src = sources[m]\n",
    "        model = src.get_model(combine=combine)\n",
    "        # Since a model can be generated for each component in a source,\n",
    "        # or all components can be combined into a single model,\n",
    "        # reshape the model if there is only a single component\n",
    "        if len(model.shape)==4:\n",
    "            components = model.shape[0]\n",
    "        else:\n",
    "            model = np.expand_dims(model, axis=0)\n",
    "\n",
    "        # Select the image patch the overlaps with the source and convert it to an RGB image\n",
    "        img_rgb = scarlet.display.img_to_rgb(images[src.bb], filter_indices=[3,2,1], norm=norm)\n",
    "\n",
    "        # Build a model for each component in the model\n",
    "        rgb = []\n",
    "        for _model in model:\n",
    "            # Convert the model to an RGB image\n",
    "            _rgb = scarlet.display.img_to_rgb(_model, filter_indices=[3,2,1], norm=norm)\n",
    "            rgb.append(_rgb)\n",
    "\n",
    "        # Display the image and model\n",
    "        figsize = [6,3]\n",
    "        columns = 2\n",
    "        # Calculate the number of columns needed and shape of the figure\n",
    "        if show_sed:\n",
    "            figsize[0] += 3\n",
    "            columns += 1\n",
    "        if not combine:\n",
    "            figsize[0] += 3*(model.shape[0]-1)\n",
    "            columns += model.shape[0]-1\n",
    "        # Build the figure\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = [fig.add_subplot(1,columns,n+1) for n in range(columns)]\n",
    "        ax[0].imshow(img_rgb)\n",
    "        ax[0].set_title(\"Data: Source {0}\".format(m))\n",
    "        for n, _rgb in enumerate(rgb):\n",
    "            ax[n+1].imshow(_rgb)\n",
    "            if combine:\n",
    "                ax[n+1].set_title(\"Initial Model\")\n",
    "            else:\n",
    "                ax[n+1].set_title(\"Component {0}\".format(n))\n",
    "        if show_sed:\n",
    "            for sed in src.sed:\n",
    "                ax[-1].plot(sed)\n",
    "            ax[-1].set_title(\"SED\")\n",
    "            ax[-1].set_xlabel(\"Band\")\n",
    "            ax[-1].set_ylabel(\"Intensity\")\n",
    "        # Mark the current source in the image\n",
    "        y,x = src.center\n",
    "        ax[0].plot(x-src.bb[2].start, y-src.bb[1].start, 'wx', mew=2)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "blend = scarlet.Blend(sources, images, bg_rms=bg_rms)\n",
    "blend.fit(50)\n",
    "\n",
    "# Set the arcsinh color scaling object\n",
    "asinh = scarlet.display.Asinh(img=images, Q=50)\n",
    "\n",
    "# For simplicity only show the first 3 peaks\n",
    "display_sources(sources, subset=[0,1,2], norm=asinh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While sources 1 and 2 look ok, we see that source 0 is clearly not monotonically decreasing from the center; if you look closely, neither is source 1.\n",
    "\n",
    "Now we'll use the direct monotonicity, which forces all of the pixels to be monotonically decreasing by starting at the center pixel and working radially outward to enforce monotonicity. This also comes in a weighted and nearest neighbor version, so for consistency we use the nearest neighbor monototonicity again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize a constraint that is used for all of the sources\n",
    "constraint = (\n",
    "    sc.SimpleConstraint() # sed sum to unity, all elements of SED and morph are non-negative\n",
    "    & sc.DirectMonotonicityConstraint(use_nearest=False) # prox_f monotonicity\n",
    "    & sc.DirectSymmetryConstraint() # prox_f perfect symmetry\n",
    ")\n",
    "\n",
    "# Initialize the Sources\n",
    "sources = [scarlet.source.PointSource(\n",
    "    (src['y'],src['x']), # center coordinates in `images`\n",
    "    images, # data cube (bands, Ny, Nx)\n",
    "    (15,15), # initial shape of the bounding box\n",
    "    constraints=constraint.copy()\n",
    ") for src in catalog]\n",
    "\n",
    "# Create the blend and display the sources\n",
    "blend = scarlet.Blend(sources, images, bg_rms=bg_rms)\n",
    "blend.fit(50)\n",
    "display_sources(sources, subset=[0,1,2], norm=asinh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see significant improvement using the direct monotonicity, even though (for reasons beyond the scope of this document) it is not an exact proximal operator.\n",
    "We have an `exact` version of the direct monotonicity, but it is too slow to be used in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Sources\n",
    "\n",
    "Many users may require specialized features that are not implemented in the existing [Source](source.ipynb#scarlet.source.Source) classes avilable so far in *scarlet*, so the framework is built to support substantial customization of the initialization and the constraint types.\n",
    "For example, the following code creates a simple bulge-disk model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BulgeDisk(scarlet.Source):\n",
    "    \"\"\"A galactic source with two components\n",
    "    \"\"\"\n",
    "    def __init__(self, center, img, config=None):\n",
    "        self.center = center\n",
    "        if config is None:\n",
    "            config = scarlet.Config()\n",
    "        # Use the smallest cache size for the initial bounding box\n",
    "        shape = (config.source_sizes[0],) * 2\n",
    "        # Use the same constraints as the default `ExtendedSource`\n",
    "        constraints = (sc.SimpleConstraint() &\n",
    "                       sc.DirectMonotonicityConstraint(use_nearest=False) &\n",
    "                       sc.SymmetryConstraint())\n",
    "        # Initialize the SEDs and morphologies for both components\n",
    "        sed, morph = self.make_initial(img, shape)\n",
    "        # NOTE: Don't forget to initialize the `Source`, as there is a lot\n",
    "        # of internal initialization\n",
    "        super(BulgeDisk, self).__init__(sed, morph, center=center, constraints=constraints)\n",
    "\n",
    "    def make_initial(self, img, shape):\n",
    "        B, Ny, Nx = img.shape\n",
    "        # A small but non-zero number\n",
    "        tiny = 1e-10\n",
    "        # center_int is a property of a `Source` that returns the\n",
    "        # integer position of the coordinates\n",
    "        _y, _x = self.center_int\n",
    "\n",
    "        # Get the color of the center pixel\n",
    "        disk_sed = scarlet.source.get_pixel_sed(img, self.center_int)\n",
    "        # Turn on all of the pixels in the box for the disk\n",
    "        disk_morph = np.zeros(shape)\n",
    "        cy = shape[0] >> 1\n",
    "        cx = shape[1] >> 1\n",
    "        dy = shape[0] >> 2\n",
    "        dx = shape[1] >> 2\n",
    "        disk_morph[cy-dy:cy+dy+1, cx-dx:cx+dx+1] = max(img[:,_y,_x].sum(axis=0), tiny)\n",
    "        disk_morph = disk_morph.reshape(shape[0]*shape[1])\n",
    "\n",
    "        # Make the bulge SED redder (and normalize)\n",
    "        bulge_sed = disk_sed + np.linspace(-0.1, 0.1, B)\n",
    "        bulge_sed /= np.sum(bulge_sed)\n",
    "        # Turn on a single pixel for the bulge\n",
    "        bulge_morph = np.zeros(shape[0] * shape[1])\n",
    "        center_pix = bulge_morph.size // 2\n",
    "        bulge_morph[center_pix] = max(img[:,_y,_x].sum(axis=0), tiny)\n",
    "\n",
    "        # Combine the two components into an initial `sed` and `morph`\n",
    "        sed = np.array([bulge_sed, disk_sed])\n",
    "        morph = np.array([bulge_morph, disk_morph]).reshape(2, shape[0], shape[1])\n",
    "        return sed, morph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this simple example a new bulge-disk model is initialized with only the central coordinates of the source and the image of the scene.\n",
    "The source is initialized with the smallest available source size (see [Configuration](#Configuration)) and uses the same constraints as an [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource), namely symmetry, monotonicity, and an SED that sums to unity (see [Constraints](#Constraints)).\n",
    "The initial SED and morphology are defined in the `make_initial` method, which initializes the morphology with a disk component that is half the size of the initial bounding box and a bulge component, which is a single pixel slightly redder than the disk.\n",
    "Finally the parent [Source](source.ipynb#scarlet.source.Source) class is initialized."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    When creating a class inherited from `Source`, don't forget to initialize the `Source`.\n",
    "    `Source.__init__` performs the initialization and configuration of parameters necessary for accessing a sources SED and morphology and projecting them properly onto the scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a list of sources with two components, initialized using the `BulgeDisk` class above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd_sources = [BulgeDisk((src[\"y\"], src[\"x\"]), images) for src in catalog]\n",
    "display_sources(bd_sources, subset=[0,1,2], norm=asinh)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. note::\n",
    "\n",
    "    The models do not exactly correspond to the specified morphology: they are translated to the position in the scence and potentially convolved with a PSF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run *scarlet* for a few iterations we see that the two components have begun to converge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bd_sources = [BulgeDisk((src[\"y\"], src[\"x\"]), images) for src in catalog]\n",
    "blend = scarlet.Blend(bd_sources, images, bg_rms=bg_rms)\n",
    "blend.fit(200)\n",
    "display_sources(blend.sources, subset=range(3), norm=asinh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blended Scenes\n",
    "\n",
    "The [Blend](blend.ipynb#scarlet.blend.Blend) class contains the entire blended scence as well as the functions to fit to data.\n",
    "\n",
    "### Configuration\n",
    "\n",
    "A number of global configuration options, used by both [Blend](blend.ipynb#scarlet.blend.Blend) and [Source](source.ipynb#scarlet.source.Source) objects, are accessed through the [Config](config.ipynb#scarlet.config.Config) class.\n",
    "See [Configuration](config.ipynb#Configuration-(scarlet.config)) for a detailed description of different configuration options.\n",
    "\n",
    "Most of the properties can be modified by the user on the fly, but changing the `Config.source_sizes` propery should be accomplished by using the [Config.set_source_sizes](config.ipynb#scarlet.config.Config.set_source_sizes) method, which ensures that all of the `source_sizes` are valid (see [Config](config.ipynb#scarlet.config.Config) for more).\n",
    "\n",
    "### Initialization\n",
    "\n",
    "Initializing a new blended scene requires a list of `sources` ([Source](#scarlet.source.Source) objects), an image (`img`) datacube with dimensions (`bands`, `height`, `width`).\n",
    "If a weightmap exists, the user can also pass a `weights` datacube with the same dimensions as `img`.\n",
    "It is also useful to pass a value for the background RMS (`bg_rms`), which is used to adjust the box size needed for each source (see the discussion in [Adjusting Sources](#Adjusting-Sources)).\n",
    "Finally an optional [Config](config.ipynb#scarlet.config.Config) class can be specified, with custom configuration options.\n",
    "\n",
    "For most users, a good place to start is by defining each source as an [ExtendedSource](source.ipynb#scarlet.source.ExtendedSource) and initializing a blend with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = [scarlet.source.ExtendedSource((src['y'],src['x']), images, bg_rms) for src in catalog]\n",
    "blend = scarlet.Blend(sources, images, bg_rms=bg_rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a scene with a collection of sources, each one with a single SED and a morphology that is both monotonic and symmetric (see [Sources](#Sources)), and will use `bg_rms` to minimize the box sizes of each source.\n",
    "\n",
    "To customize the configuration of the [Blend](blend.ipynb#scarlet.blend.Blend), for example using a lower flux threshold for resizing source bounding boxes, a [Blend](blend.ipynb#scarlet.blend.Blend) can be initialized with a new [Config](config.ipynb#scarlet.config.Config)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = scarlet.Config(edge_flux_thresh=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which will resize the box if the model has flux along any edge that us greater than `Config.edge_flux_thresh*bg_rms`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. warning::\n",
    "\n",
    "    A number of internal properties are set when a `Blend` instance is created.\n",
    "    If it is necessary to add or remove sources at a later time, it is best to create a new `Blend` using the new source list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Model\n",
    "\n",
    "The [Blend](blend.ipynb#scarlet.blend.Blend) class implement the minimization algorithm described in [Moolekamp & Melchior 2018](https://arxiv.org/abs/1708.09066). See details [above](#Basic-Concepts-and-Structure).\n",
    "\n",
    "The [Blend.fit](blend.ipynb#scarlet.blend.Blend.fit) method will fit the current model and requires two parameters: the maximum number of `steps` (or iterations) used to fit the data and the relative error for convergence (`e_rel`).\n",
    "It stops if one of the following conditions is met:\n",
    "\n",
    "1. The total number of iterations is equal to `steps`\n",
    "\n",
    "1. The model converges (as defined in  [Moolekamp & Melchior 2018](https://arxiv.org/abs/1708.09066)).\n",
    "\n",
    "\n",
    "### Restarting a Fit\n",
    "\n",
    "There may be instances where it is desirable to restart a fit.\n",
    "For example, after a certain number of iterations inspect the result even prior to convergence, or you may have a custom constraint that you want to apply every Nth iteration.\n",
    "In that case you can call `Blend.fit(N1)` and continue with another call to `Blend.fit(N2)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = [scarlet.source.ExtendedSource((src['y'],src['x']), images, bg_rms) for src in catalog]\n",
    "blend = scarlet.Blend(sources, images, bg_rms=bg_rms)\n",
    "blend.fit(20)\n",
    "print(blend.it)\n",
    "blend.fit(20)\n",
    "print(blend.it)\n",
    "blend.fit(20)\n",
    "print(blend.it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we see that the last fit the blend converged before reaching 60 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting Sources\n",
    "\n",
    "In most blends the number of non-zero pixels is much smaller than the total number of pixels in the image.\n",
    "To save processing time we recommend initializing sources with a small number of pixels and allowing the [Blend.fit](blend.ipynb#scarlet.blend.Blend.fit) method to expand the size of the box.\n",
    "This happens automatically for every source with `fix_frame=False` when that source's morphology has any flux above `config.edge_flux_thresh*blend.bg_rms` along the edge of its current bounding box.\n",
    "\n",
    "With the default [symmetry](#Symmetry) and [monotonicity](#Monotonicity) constraints the model is dependent on the accuracy of the center position for each source.\n",
    "The [Blend.recenter_sources](blend.ipynb#scarlet.blend.Blend.recenter_sources) method recenters all sources with `shift_center > 0` simultaneously by calculateing the shifts needed to align the models with the data to null any residual dipoles.\n",
    "\n",
    "Both resizing sources and recentering sources are expensive operations (as resizing requires rebuilding all of the constraint operators and recentering requires building a shifted model) and are thus only performed every `Config.refine_skip` iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Individual Sources and Components\n",
    "\n",
    "Internally the algorithm operates on the space of components, not sources (where a single [Source](#scarlet.source.Source) might have multiple components), so a [Blend](blend.ipynb#scarlet.blend.Blend) contains a number of indexing properties to convert from component space to source space.\n",
    "\n",
    "For example, a `blend` created using the `BulgeDisk` class has two components for each source, for a total of 2$\\times$sources components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd_sources = [BulgeDisk((src[\"y\"], src[\"x\"]), images) for src in catalog]\n",
    "blend = scarlet.Blend(bd_sources, images, bg_rms=bg_rms)\n",
    "print(\"Number of sources:\", blend.M)\n",
    "print(\"Number of components:\", blend.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we iterate through the sources we can find the index of the component in `blend`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m, src in enumerate(blend.sources):\n",
    "    for l in range(src.K):\n",
    "        k = blend.component_of(m,l)\n",
    "        print(\"Component {0} has index {1}\".format((m,l),k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can use the index of the model component $k$ to find the index of the source, and the index of the component inside that source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(blend.K):\n",
    "    m,l = blend.source_of(k)\n",
    "    print(\"Component {0} is component {1} in source {2}\".format(k, l, m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Blend](blend.ipynb#scarlet.blend.Blend) also has a `__len__` method, so taking the length of `blend` gives the number of sources (not components):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(blend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loading and Displaying a Model\n",
    "\n",
    "### Display functions\n",
    "\n",
    "The [display](display.ipynb) module contains a number of convenience methods to convert an image cube into an RGB image array.\n",
    "\n",
    "There are two stock classes used to scale the pixels in the image, [Linear](display.ipynb#scarlet.display.Linear) and [Asinh](display.ipynb#scarlet.display.Asinh), both of which inherit from the `matplotlib.colors.Normalize` class.\n",
    "This inheritance allows them to be used as normalizations in `matplotlib.pyplot.imshow`, including an `inverse` method that makes it possible to add a colorbar.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = scarlet.display.Linear(img=images)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Linear Scaling\")\n",
    "plt.show()\n",
    "\n",
    "norm = scarlet.display.Asinh(img=images)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Asinh Scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Linear](display.ipynb#scarlet.display.Linear) class is fairly straightforward, allowing the user to (optionally) pass `vmin` and `vmax` parameters to set the range of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = scarlet.display.Linear(vmin=0, vmax=100)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Linear Scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Asinh](display.ipynb#scarlet.display.Asinh) scaling is popular because it is linear for small values and logrithmic for larger fluxes, allowing it to display a wide range of intensities clearly.\n",
    "The actual formula used to scale each pixel is\n",
    "\n",
    "$$f(x) = \\frac{1}{Q} \\sinh^{-1} \\left( Q \\frac{x-v_\\textrm{min}}{v_\\textrm{max}-v_\\textrm{min}} \\right)$$\n",
    "\n",
    "where `Q` is a parameter that defines the strech of the scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = scarlet.display.Asinh(img=images, vmin=0, Q=10)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Asinh Scaling\")\n",
    "plt.show()\n",
    "\n",
    "norm = scarlet.display.Asinh(img=images, vmin=0, Q=100)\n",
    "plt.imshow(images[2], norm=norm)\n",
    "plt.colorbar()\n",
    "plt.title(\"Asinh Scaling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image cube can be converted from a (bands, height, width) array into an RGB image array using the [img_to_rgb](display.ipynb#scarlet.display.img_to_rgb) function.\n",
    "This allows the user to specify a normalization (`norm`), `fill_value` (value to use for any masked pixels), and list of indices to map to R, G, B respectively (`filter_indices`).\n",
    "For example the default is to map the first three bands in reverse order to RGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rgb = scarlet.display.img_to_rgb(images, norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the mapping is $r \\rightarrow R$, $g \\rightarrow G$, $u \\rightarrow B$.\n",
    "A more natural mapping (and the one used in most of this document) is $i \\rightarrow R$, $r \\rightarrow G$, $g \\rightarrow B$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rgb = scarlet.display.img_to_rgb(images, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Models from a Blend\n",
    "\n",
    "You can load the models that make up a scene at any time, even if the blend has been initialized but not fit for a single iteration. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the blend but don't fit the model\n",
    "bd_sources = [BulgeDisk((src[\"y\"], src[\"x\"]), images) for src in catalog]\n",
    "blend = scarlet.Blend(bd_sources, images, bg_rms=bg_rms)\n",
    "model = blend.get_model()\n",
    "img_rgb = scarlet.display.img_to_rgb(model, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to load the model for each source individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = blend.get_model(\n",
    "    combine=False, # Don't combine the model for each source together\n",
    "    flat=False # Don't flatten the model, keeping each component separate\n",
    ")\n",
    "img_rgb = scarlet.display.img_to_rgb(models[0], filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or even by component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a model \n",
    "model = blend.get_model(\n",
    "    m=0, # index of the first source\n",
    "    combine=False, # Don't combine the model for each source together\n",
    "    combine_source_components=False # Don't combine the components into a single model for each source\n",
    ")\n",
    "# Display the bulge\n",
    "img_rgb = scarlet.display.img_to_rgb(model[0], filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()\n",
    "# Display the disk\n",
    "img_rgb = scarlet.display.img_to_rgb(model[1], filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might also want to extract just the morphology (without convolving with the SED). To prevent unexpected results (i.e. the model having a different shape depending on the given parameters) the resulting model will still have the shape (`components`, `bands`, `height`, `width`), however there are only `components` different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a few iterations, jsut to make the model more interesting\n",
    "blend.fit(100)\n",
    "model = blend.get_model(\n",
    "    m=0, # index of the first source\n",
    "    combine=False, # Don't combine the model for each source together\n",
    "    combine_source_components=False, # Don't combine the components into a single model for each source\n",
    "    use_sed=False # Don't convolve with the SED\n",
    ")\n",
    "plt.imshow(model[0][1])\n",
    "plt.show()\n",
    "plt.imshow(model[0][3])\n",
    "plt.show()\n",
    "plt.imshow(model[1][1])\n",
    "plt.show()\n",
    "plt.imshow(model[1][2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Models from a Source\n",
    "\n",
    "It is also possible to access the morphology of a given source directly, which is always centered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = blend.sources[0]\n",
    "plt.imshow(src.morph[0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(src.morph[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `src.image` is the same as `src.morph.reshape(src.K, src.Ny, src.Nx)`.\n",
    "Notice how in this space only the part of the model inside the bounding box is given, since this is the space where the morphology lives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the SED for each source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m, src in enumerate(blend.sources):\n",
    "    # Only display the SED for the bulge components\n",
    "    plt.plot(src.sed[0], label=m)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to extract the model for a given source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = src.get_model()\n",
    "_model = scarlet.display.img_to_rgb(model, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = src.get_model(combine=False)\n",
    "_model = scarlet.display.img_to_rgb(model[0], filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or without recentering  or PSF convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gamma = src._gamma(dyx=[0,0])\n",
    "model = src.get_model(Gamma=Gamma)\n",
    "_model = scarlet.display.img_to_rgb(model, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works because the `Source._gammaOp` is an operator that handles psf convolution and translation. This part of the code is likely to change in the near future, so we won't give a detailed description of how this is implementd in the code. But basically, `Source._gammaOp([dy,dx])` performs a psf convolution (if a psf was specified) and a linear shift by $dx$ and $dy$, the fraction of a pixel to move in the $x$ and $y$ directions respectively.\n",
    "\n",
    "## Other Useful Source Properties\n",
    "\n",
    "Below are a list of properties that can be accessed for a source. For more information about them, see [Source](source.ipynb#scarlet.source.Source)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = blend.sources[1]\n",
    "print(\"Source shape:\", src.shape)\n",
    "print(\"Source dimensions:\", (src.Ny, src.Nx))\n",
    "print(\"Center:\", src.center)\n",
    "print(\"integer center:\", src.center_int)\n",
    "print(\"Slice of the original image to fit the source:\", src.get_slice_for(images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the image centered on the source, where `Source.bb` is the bounding box to extract the source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_img = images[src.bb]\n",
    "img_rgb = scarlet.display.img_to_rgb(_img, filter_indices=[3,2,1], norm=asinh)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a source is on the edge then it might be necessary to extract only part of the full source using [Source.get_slice_for](source.ipynb#scarlet.source.Source.get_slice_for), where `source.image[source.get_slice_for(images.shape)]` is the same shape and aligned with `images[source.bb]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,3))\n",
    "ax = [fig.add_subplot(1,2,1+n) for n in range(2)]\n",
    "ax[0].imshow(img_rgb)\n",
    "_img = scarlet.display.img_to_rgb(src.get_model()[src.get_slice_for(images.shape)], filter_indices=[3,2,1], norm=asinh)\n",
    "ax[1].imshow(_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the overview. The user is referred to the [API Documentation](api_docs.rst) for more details about the objects used in *scarlet*."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
